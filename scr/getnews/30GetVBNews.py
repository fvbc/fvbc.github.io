
# module
import arrow
import requests
from bs4 import BeautifulSoup


# main

#OutFile = 'vbnews.html'
OutFile = 'vbinfo.html'

# ================================================================================================================
# HTMLå†’é ­
# ================================================================================================================

HtmlBody = "<html>\n<head>\n<title>Volleyball News</title>\n<link rel=\"stylesheet\" href=\"style.css\">\n</head>\n<body>\n"
HtmlBody += "<div class=\"bg_pattern Diagonal_v2\"></div>\n"

JPNow = arrow.now('Asia/Tokyo')
WeekList = ['æ—¥','æœˆ','ç«','æ°´','æœ¨','é‡‘','åœŸ']
HtmlBody += 'æ›´æ–°æ—¥æ™‚: ' + JPNow.format('YYYY/MM/DD ') + WeekList[int(JPNow.format('d'))] + JPNow.format(' HH:mm') + "<br>\n"


# ================================================================================================================
# å‚è€ƒãƒªã‚½ãƒ¼ã‚¹
# ================================================================================================================
HtmlBody += "<p>ã€ ãƒãƒ¬ãƒ¼ãƒœãƒ¼ãƒ«å°å­¦ç”Ÿãƒ«ãƒ¼ãƒ« ã€‘</p>\n"
HtmlBody += f"<a href=\"https://jeva-web.com/wsyst/wp-content/uploads/2023/04/2023_kyougikisoku.pdf\" target=\"_blank\" rel=\"noopener noreferrer\"> ğŸ å°å­¦ç”Ÿãƒãƒ¬ãƒ¼ãƒœãƒ¼ãƒ«ç«¶æŠ€è¦å‰‡ [æ—¥æœ¬å°å­¦ç”Ÿãƒãƒ¬ãƒ¼ãƒœãƒ¼ãƒ«é€£ç›Ÿ]</a><br>\n"


# ================================================================================================================
# ãƒãƒ¬ãƒ¼RSS
# ================================================================================================================
HtmlBody += "<p>ã€ æ³¨ç›®ãƒ‹ãƒ¥ãƒ¼ã‚¹ ã€‘</p>\n"
FeedList = ['https://news.yahoo.co.jp/rss/media/getsuv/all.xml', 'https://news.yahoo.co.jp/rss/media/vbm/all.xml']

# å„ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å·¡å›ã™ã‚‹ç¹°ã‚Šè¿”ã—
for FeedURL in FeedList:
  print(FeedURL)

  # RSSã®å–å¾—
  # URLã«æ¥ç¶šã—ã¦æƒ…å ±å–å¾—
  r = requests.get(FeedURL)
  
  # ã‚½ãƒ¼ã‚¹ã‚’HTMLã¨ã—ã¦è§£é‡ˆã—ã¦å–å¾—
  HTMLStr = r.text
  soup = BeautifulSoup(HTMLStr, 'lxml-xml')

  # ã‚¢ã‚¤ãƒ†ãƒ ã®åˆ†æã¨HTMLã®ä½œæˆ
  # ã‚¿ã‚¤ãƒˆãƒ«
  HtmlBody += "<p>====================================<br>\n"
  HtmlBody += f"<a href=\"{soup.link.string}\" target=\"_blank\" rel=\"noopener noreferrer\"> ğŸ {soup.title.string}</a><br>\n"
  HtmlBody += "====================================</p>\n"
  HtmlBody += "<ul>\n"

  for item in soup.findAll('item'):
#    print(f"<a href=\"{item.link.string}\">{item.title.string}</a>")
#    HtmlBody += f"<p><a href=\"{item.link.string}\" target=\"_blank\" rel=\"noopener noreferrer\">{item.title.string}</a></p><br>\n"
    HtmlBody += f"  <li><a href=\"{item.link.string}\" target=\"_blank\" rel=\"noopener noreferrer\">\n  {item.title.string}</a></li>\n"
    DescriStr = item.description.string.replace('\n','').replace('\u3000','')
    HtmlBody += f"  <p>ã€€{DescriStr}...</p>\n"
  HtmlBody += "</ul>"
  HtmlBody += "<br>\n"


# ================================================================================================================
# HTMLæœ«å°¾
# ================================================================================================================
HtmlBody += "\n</body>\n</html>\n"
# print(HtmlBody)


# ================================================================================================================
# HTMLæ›¸ãå‡ºã—
# ================================================================================================================
with open(OutFile, "w") as file:
    file.writelines(HtmlBody)

